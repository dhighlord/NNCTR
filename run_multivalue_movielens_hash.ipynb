{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_multivalue_movielens_hash.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhighlord/NNCTR/blob/master/run_multivalue_movielens_hash.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aVgTErJxPYt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "64cbf682-38fd-466b-a374-31151e6306c1"
      },
      "source": [
        "!git clone https://github.com/dhighlord/NNCTR.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NNCTR'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "Unpacking objects:   1% (1/75)   \rUnpacking objects:   2% (2/75)   \rUnpacking objects:   4% (3/75)   \rUnpacking objects:   5% (4/75)   \rUnpacking objects:   6% (5/75)   \rUnpacking objects:   8% (6/75)   \rUnpacking objects:   9% (7/75)   \rUnpacking objects:  10% (8/75)   \rUnpacking objects:  12% (9/75)   \rUnpacking objects:  13% (10/75)   \rUnpacking objects:  14% (11/75)   \rUnpacking objects:  16% (12/75)   \rUnpacking objects:  17% (13/75)   \rUnpacking objects:  18% (14/75)   \rUnpacking objects:  20% (15/75)   \rUnpacking objects:  21% (16/75)   \rUnpacking objects:  22% (17/75)   \rUnpacking objects:  24% (18/75)   \rUnpacking objects:  25% (19/75)   \rUnpacking objects:  26% (20/75)   \rUnpacking objects:  28% (21/75)   \rUnpacking objects:  29% (22/75)   \rUnpacking objects:  30% (23/75)   \rUnpacking objects:  32% (24/75)   \rUnpacking objects:  33% (25/75)   \rUnpacking objects:  34% (26/75)   \rUnpacking objects:  36% (27/75)   \rUnpacking objects:  37% (28/75)   \rUnpacking objects:  38% (29/75)   \rUnpacking objects:  40% (30/75)   \rUnpacking objects:  41% (31/75)   \rUnpacking objects:  42% (32/75)   \rUnpacking objects:  44% (33/75)   \rUnpacking objects:  45% (34/75)   \rUnpacking objects:  46% (35/75)   \rUnpacking objects:  48% (36/75)   \rUnpacking objects:  49% (37/75)   \rUnpacking objects:  50% (38/75)   \rUnpacking objects:  52% (39/75)   \rUnpacking objects:  53% (40/75)   \rUnpacking objects:  54% (41/75)   \rUnpacking objects:  56% (42/75)   \rUnpacking objects:  57% (43/75)   \rremote: Total 75 (delta 2), reused 0 (delta 0), pack-reused 69\u001b[K\n",
            "Unpacking objects:  58% (44/75)   \rUnpacking objects:  60% (45/75)   \rUnpacking objects:  61% (46/75)   \rUnpacking objects:  62% (47/75)   \rUnpacking objects:  64% (48/75)   \rUnpacking objects:  65% (49/75)   \rUnpacking objects:  66% (50/75)   \rUnpacking objects:  68% (51/75)   \rUnpacking objects:  69% (52/75)   \rUnpacking objects:  70% (53/75)   \rUnpacking objects:  72% (54/75)   \rUnpacking objects:  73% (55/75)   \rUnpacking objects:  74% (56/75)   \rUnpacking objects:  76% (57/75)   \rUnpacking objects:  77% (58/75)   \rUnpacking objects:  78% (59/75)   \rUnpacking objects:  80% (60/75)   \rUnpacking objects:  81% (61/75)   \rUnpacking objects:  82% (62/75)   \rUnpacking objects:  84% (63/75)   \rUnpacking objects:  85% (64/75)   \rUnpacking objects:  86% (65/75)   \rUnpacking objects:  88% (66/75)   \rUnpacking objects:  89% (67/75)   \rUnpacking objects:  90% (68/75)   \rUnpacking objects:  92% (69/75)   \rUnpacking objects:  93% (70/75)   \rUnpacking objects:  94% (71/75)   \rUnpacking objects:  96% (72/75)   \rUnpacking objects:  97% (73/75)   \rUnpacking objects:  98% (74/75)   \rUnpacking objects: 100% (75/75)   \rUnpacking objects: 100% (75/75), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpaaciDY5AiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from NNCTR.deepctr.models import DeepFM\n",
        "from NNCTR.deepctr.inputs import SparseFeat, VarLenSparseFeat,get_fixlen_feature_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj6SHb9u5H7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "436aac5d-a4b8-4cd1-beff-b58e36c9b9d9"
      },
      "source": [
        "data = pd.read_csv(\"NNCTR/examples/movielens_sample.txt\")\n",
        "sparse_features = [\"movie_id\", \"user_id\",\n",
        "                   \"gender\", \"age\", \"occupation\", \"zip\", ]\n",
        "\n",
        "data[sparse_features] = data[sparse_features].astype(str)\n",
        "target = ['rating']\n",
        "\n",
        "# 1.Use hashing encoding on the fly for sparse features,and process sequence features\n",
        "\n",
        "genres_list = list(map(lambda x: x.split('|'), data['genres'].values))\n",
        "genres_length = np.array(list(map(len, genres_list)))\n",
        "max_len = max(genres_length)\n",
        "\n",
        "# Notice : padding=`post`\n",
        "genres_list = pad_sequences(genres_list, maxlen=max_len, padding='post', dtype=str, value=0)\n",
        "\n",
        "# 2.set hashing space for each sparse field and generate feature config for sequence feature\n",
        "\n",
        "fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique() * 5, use_hash=True, dtype='string')\n",
        "                          for feat in sparse_features]\n",
        "varlen_feature_columns = [VarLenSparseFeat('genres', 100, max_len, 'mean', use_hash=True,\n",
        "                                           dtype=\"string\")]  # Notice : value 0 is for padding for sequence input feature\n",
        "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
        "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
        "feature_names = get_fixlen_feature_names(linear_feature_columns + dnn_feature_columns)\n",
        "\n",
        "# 3.generate input data for model\n",
        "fixlen_input = [data[name].values for name in feature_names]\n",
        "varlen_input = [genres_list]\n",
        "\n",
        "model_input = fixlen_input + varlen_input # make sure the order is right\n",
        "\n",
        "# 4.Define Model,compile and train\n",
        "model = DeepFM(linear_feature_columns,dnn_feature_columns, task='regression')\n",
        "\n",
        "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
        "history = model.fit(model_input, data[target].values,\n",
        "                    batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0809 10:20:21.148170 140396070111104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0809 10:20:21.363442 140396070111104 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
            "\n",
            "W0809 10:20:22.241670 140396070111104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:253: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "W0809 10:20:22.349387 140396070111104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:253: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0809 10:20:22.617973 140396070111104 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 160 samples, validate on 40 samples\n",
            "Epoch 1/10\n",
            "160/160 - 1s - loss: 14.3009 - mean_squared_error: 14.3009 - val_loss: 13.3791 - val_mean_squared_error: 13.3791\n",
            "Epoch 2/10\n",
            "160/160 - 0s - loss: 14.1576 - mean_squared_error: 14.1576 - val_loss: 13.2492 - val_mean_squared_error: 13.2492\n",
            "Epoch 3/10\n",
            "160/160 - 0s - loss: 14.0041 - mean_squared_error: 14.0041 - val_loss: 13.1089 - val_mean_squared_error: 13.1089\n",
            "Epoch 4/10\n",
            "160/160 - 0s - loss: 13.8389 - mean_squared_error: 13.8389 - val_loss: 12.9594 - val_mean_squared_error: 12.9594\n",
            "Epoch 5/10\n",
            "160/160 - 0s - loss: 13.6629 - mean_squared_error: 13.6629 - val_loss: 12.8001 - val_mean_squared_error: 12.8001\n",
            "Epoch 6/10\n",
            "160/160 - 0s - loss: 13.4755 - mean_squared_error: 13.4755 - val_loss: 12.6301 - val_mean_squared_error: 12.6301\n",
            "Epoch 7/10\n",
            "160/160 - 0s - loss: 13.2757 - mean_squared_error: 13.2757 - val_loss: 12.4482 - val_mean_squared_error: 12.4482\n",
            "Epoch 8/10\n",
            "160/160 - 0s - loss: 13.0618 - mean_squared_error: 13.0618 - val_loss: 12.2535 - val_mean_squared_error: 12.2535\n",
            "Epoch 9/10\n",
            "160/160 - 0s - loss: 12.8323 - mean_squared_error: 12.8323 - val_loss: 12.0447 - val_mean_squared_error: 12.0447\n",
            "Epoch 10/10\n",
            "160/160 - 0s - loss: 12.5853 - mean_squared_error: 12.5853 - val_loss: 11.8207 - val_mean_squared_error: 11.8207\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}